{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSDvWlOV3DSz6Caeg3OzRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santhoshsingam/html-portfolio/blob/main/pcb_defect_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install all necessary packages\n",
        "!pip install ultralytics opencv-python pillow matplotlib requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQEhHNtkjYZd",
        "outputId": "caec4704-a374-4101-f7f3-bb754d53611b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.226-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.226-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.226 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import all required libraries\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIEHHm5SjbLy",
        "outputId": "a0d23655-fa89-431b-891b-9060e149e755"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úÖ All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Download the PCB dataset\n",
        "def download_and_setup_dataset():\n",
        "    print(\"üì• Downloading PCB Defects dataset...\")\n",
        "\n",
        "    # URL from the provided Dropbox link\n",
        "    dataset_url = \"https://www.dropbox.com/s/32kolsaa45z2mpj/PCB_DATASET.zip?dl=1\"\n",
        "    zip_path = \"/content/PCB_DATASET.zip\"\n",
        "    extract_path = \"/content/PCB_DATASET\"\n",
        "\n",
        "    # Download the dataset\n",
        "    print(\"Downloading... This may take a few minutes.\")\n",
        "    response = requests.get(dataset_url, stream=True)\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "    with open(zip_path, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "\n",
        "    print(f\"‚úÖ Download complete! File size: {os.path.getsize(zip_path) / (1024*1024):.2f} MB\")\n",
        "\n",
        "    # Extract the dataset\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    print(\"‚úÖ Extraction complete!\")\n",
        "    return extract_path\n",
        "\n",
        "# Execute download\n",
        "dataset_path = download_and_setup_dataset()\n",
        "print(f\"Dataset located at: {dataset_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_oWtRhNjgEA",
        "outputId": "b020b4da-a8b9-4855-ce38-c381adbed11b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading PCB Defects dataset...\n",
            "Downloading... This may take a few minutes.\n",
            "‚úÖ Download complete! File size: 1918.76 MB\n",
            "Extracting dataset...\n",
            "‚úÖ Extraction complete!\n",
            "Dataset located at: /content/PCB_DATASET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Explore what's in the dataset\n",
        "def explore_dataset(dataset_path):\n",
        "    print(\"\\nüìÅ Exploring dataset structure...\")\n",
        "\n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        level = root.replace(dataset_path, '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f'{indent}üìÅ {os.path.basename(root)}/')\n",
        "\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        image_files = [f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        annotation_files = [f for f in files if f.lower().endswith(('.txt', '.xml', '.json'))]\n",
        "\n",
        "        for img_file in image_files[:3]:  # Show first 3 images\n",
        "            print(f'{subindent}üñºÔ∏è  {img_file}')\n",
        "        if len(image_files) > 3:\n",
        "            print(f'{subindent}... and {len(image_files) - 3} more images')\n",
        "\n",
        "        for ann_file in annotation_files[:3]:  # Show first 3 annotations\n",
        "            print(f'{subindent}üìÑ {ann_file}')\n",
        "        if len(annotation_files) > 3:\n",
        "            print(f'{subindent}... and {len(annotation_files) - 3} more annotation files')\n",
        "\n",
        "    return all_files\n",
        "\n",
        "# Explore the dataset\n",
        "explore_dataset(dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aIhlGAijwJR",
        "outputId": "fa74d277-d849-4e25-e319-20f7f799a34c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Exploring dataset structure...\n",
            "üìÅ PCB_DATASET/\n",
            "  üìÅ PCB_DATASET/\n",
            "    üìÅ Annotations/\n",
            "      üìÅ Open_circuit/\n",
            "        üìÑ 06_open_circuit_01.xml\n",
            "        üìÑ 07_open_circuit_04.xml\n",
            "        üìÑ 05_open_circuit_02.xml\n",
            "        ... and 113 more annotation files\n",
            "      üìÅ Short/\n",
            "        üìÑ 05_short_07.xml\n",
            "        üìÑ 08_short_05.xml\n",
            "        üìÑ 07_short_02.xml\n",
            "        ... and 113 more annotation files\n",
            "      üìÅ Spur/\n",
            "        üìÑ 06_spur_09.xml\n",
            "        üìÑ 09_spur_08.xml\n",
            "        üìÑ 01_spur_13.xml\n",
            "        ... and 112 more annotation files\n",
            "      üìÅ Mouse_bite/\n",
            "        üìÑ 11_mouse_bite_10.xml\n",
            "        üìÑ 01_mouse_bite_03.xml\n",
            "        üìÑ 11_mouse_bite_06.xml\n",
            "        ... and 112 more annotation files\n",
            "      üìÅ Missing_hole/\n",
            "        üìÑ 12_missing_hole_07.xml\n",
            "        üìÑ 04_missing_hole_11.xml\n",
            "        üìÑ 01_missing_hole_05.xml\n",
            "        ... and 112 more annotation files\n",
            "      üìÅ Spurious_copper/\n",
            "        üìÑ 05_spurious_copper_08.xml\n",
            "        üìÑ 01_spurious_copper_12.xml\n",
            "        üìÑ 08_spurious_copper_02.xml\n",
            "        ... and 113 more annotation files\n",
            "    üìÅ rotation/\n",
            "      üìÑ Open_circuit_angles.txt\n",
            "      üìÑ Spur_angles.txt\n",
            "      üìÑ Short_angles.txt\n",
            "      ... and 3 more annotation files\n",
            "      üìÅ Missing_hole_rotation/\n",
            "        üñºÔ∏è  11_missing_hole_04.jpg\n",
            "        üñºÔ∏è  06_missing_hole_09.jpg\n",
            "        üñºÔ∏è  09_missing_hole_05.jpg\n",
            "        ... and 112 more images\n",
            "      üìÅ Spur_rotation/\n",
            "        üñºÔ∏è  01_spur_09.jpg\n",
            "        üñºÔ∏è  08_spur_04.jpg\n",
            "        üñºÔ∏è  06_spur_08.jpg\n",
            "        ... and 112 more images\n",
            "      üìÅ Mouse_bite_rotation/\n",
            "        üñºÔ∏è  05_mouse_bite_08.jpg\n",
            "        üñºÔ∏è  09_mouse_bite_02.jpg\n",
            "        üñºÔ∏è  04_mouse_bite_17.jpg\n",
            "        ... and 112 more images\n",
            "      üìÅ Spurious_copper_rotation/\n",
            "        üñºÔ∏è  12_spurious_copper_03.jpg\n",
            "        üñºÔ∏è  01_spurious_copper_14.jpg\n",
            "        üñºÔ∏è  04_spurious_copper_01.jpg\n",
            "        ... and 113 more images\n",
            "      üìÅ Short_rotation/\n",
            "        üñºÔ∏è  09_short_03.jpg\n",
            "        üñºÔ∏è  11_short_02.jpg\n",
            "        üñºÔ∏è  12_short_03.jpg\n",
            "        ... and 113 more images\n",
            "      üìÅ Open_circuit_rotation/\n",
            "        üñºÔ∏è  07_open_circuit_10.jpg\n",
            "        üñºÔ∏è  12_open_circuit_03.jpg\n",
            "        üñºÔ∏è  07_open_circuit_09.jpg\n",
            "        ... and 113 more images\n",
            "    üìÅ PCB_USED/\n",
            "      üñºÔ∏è  07.JPG\n",
            "      üñºÔ∏è  05.JPG\n",
            "      üñºÔ∏è  12.JPG\n",
            "      ... and 7 more images\n",
            "    üìÅ images/\n",
            "      üìÅ Open_circuit/\n",
            "        üñºÔ∏è  07_open_circuit_10.jpg\n",
            "        üñºÔ∏è  12_open_circuit_03.jpg\n",
            "        üñºÔ∏è  07_open_circuit_09.jpg\n",
            "        ... and 113 more images\n",
            "      üìÅ Short/\n",
            "        üñºÔ∏è  09_short_03.jpg\n",
            "        üñºÔ∏è  11_short_02.jpg\n",
            "        üñºÔ∏è  12_short_03.jpg\n",
            "        ... and 113 more images\n",
            "      üìÅ Spur/\n",
            "        üñºÔ∏è  01_spur_09.jpg\n",
            "        üñºÔ∏è  08_spur_04.jpg\n",
            "        üñºÔ∏è  06_spur_08.jpg\n",
            "        ... and 112 more images\n",
            "      üìÅ Mouse_bite/\n",
            "        üñºÔ∏è  05_mouse_bite_08.jpg\n",
            "        üñºÔ∏è  09_mouse_bite_02.jpg\n",
            "        üñºÔ∏è  04_mouse_bite_17.jpg\n",
            "        ... and 112 more images\n",
            "      üìÅ Missing_hole/\n",
            "        üñºÔ∏è  11_missing_hole_04.jpg\n",
            "        üñºÔ∏è  06_missing_hole_09.jpg\n",
            "        üñºÔ∏è  09_missing_hole_05.jpg\n",
            "        ... and 112 more images\n",
            "      üìÅ Spurious_copper/\n",
            "        üñºÔ∏è  12_spurious_copper_03.jpg\n",
            "        üñºÔ∏è  01_spurious_copper_14.jpg\n",
            "        üñºÔ∏è  04_spurious_copper_01.jpg\n",
            "        ... and 113 more images\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download the AUGMENTED dataset with 10,668 images\n",
        "def download_augmented_dataset():\n",
        "    print(\"üì• Downloading AUGMENTED PCB Dataset (10k+ images)...\")\n",
        "\n",
        "    # Use the AUGMENTED dataset link from the README\n",
        "    augmented_dataset_url = \"https://www.dropbox.com/s/h0f39nyotddibsb/VOC_PCB.zip?dl=1\"\n",
        "    zip_path = \"/content/VOC_PCB.zip\"\n",
        "    extract_path = \"/content/VOC_PCB\"\n",
        "\n",
        "    # Download the dataset\n",
        "    print(\"Downloading AUGMENTED dataset (this will take longer, ~1-2GB)...\")\n",
        "    response = requests.get(augmented_dataset_url, stream=True)\n",
        "\n",
        "    with open(zip_path, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "\n",
        "    file_size = os.path.getsize(zip_path) / (1024*1024*1024)  # Size in GB\n",
        "    print(f\"‚úÖ Download complete! File size: {file_size:.2f} GB\")\n",
        "\n",
        "    # Extract the dataset\n",
        "    print(\"Extracting AUGMENTED dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    print(\"‚úÖ Extraction complete!\")\n",
        "    return extract_path\n",
        "\n",
        "# Download the CORRECT dataset\n",
        "print(\"üîÑ Replacing the small dataset with the LARGE 10k+ images dataset...\")\n",
        "augmented_dataset_path = download_augmented_dataset()\n",
        "print(f\"Large dataset located at: {augmented_dataset_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCtcnhJhjzXd",
        "outputId": "6ae58da5-276d-4baa-9721-0bfc209af316"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Replacing the small dataset with the LARGE 10k+ images dataset...\n",
            "üì• Downloading AUGMENTED PCB Dataset (10k+ images)...\n",
            "Downloading AUGMENTED dataset (this will take longer, ~1-2GB)...\n",
            "‚úÖ Download complete! File size: 1.10 GB\n",
            "Extracting AUGMENTED dataset...\n",
            "‚úÖ Extraction complete!\n",
            "Large dataset located at: /content/VOC_PCB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Explore the 10k+ images dataset\n",
        "def explore_augmented_dataset(dataset_path):\n",
        "    print(\"\\nüìÅ Exploring AUGMENTED dataset structure...\")\n",
        "\n",
        "    total_images = 0\n",
        "    total_annotations = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        level = root.replace(dataset_path, '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "\n",
        "        image_files = [f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        annotation_files = [f for f in files if f.lower().endswith(('.txt', '.xml', '.json'))]\n",
        "\n",
        "        total_images += len(image_files)\n",
        "        total_annotations += len(annotation_files)\n",
        "\n",
        "        if image_files or annotation_files:\n",
        "            print(f'{indent}üìÅ {os.path.basename(root)}/')\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "\n",
        "            if image_files:\n",
        "                print(f'{subindent}üñºÔ∏è  {len(image_files)} images')\n",
        "            if annotation_files:\n",
        "                print(f'{subindent}üìÑ {len(annotation_files)} annotations')\n",
        "\n",
        "    print(f\"\\nüéØ TOTAL IMAGES: {total_images}\")\n",
        "    print(f\"üéØ TOTAL ANNOTATIONS: {total_annotations}\")\n",
        "\n",
        "    return total_images\n",
        "\n",
        "# Explore the large dataset\n",
        "total_images = explore_augmented_dataset(augmented_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqvvDskQkxTF",
        "outputId": "1d0db9f9-ea3e-4075-886d-c8843926c090"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Exploring AUGMENTED dataset structure...\n",
            "      üìÅ Main/\n",
            "        üìÑ 4 annotations\n",
            "    üìÅ Annotations/\n",
            "      üìÑ 10668 annotations\n",
            "    üìÅ JPEGImages/\n",
            "      üñºÔ∏è  10668 images\n",
            "\n",
            "üéØ TOTAL IMAGES: 10668\n",
            "üéØ TOTAL ANNOTATIONS: 10672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Count images in detail\n",
        "def count_images_detailed(dataset_path):\n",
        "    print(\"\\nüî¢ Detailed image count...\")\n",
        "\n",
        "    image_counts = {}\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        image_files = [f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        if image_files:\n",
        "            folder_name = os.path.basename(root)\n",
        "            image_counts[folder_name] = len(image_files)\n",
        "\n",
        "    # Sort by count\n",
        "    sorted_counts = sorted(image_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"\\nüìä IMAGE COUNT BY FOLDER:\")\n",
        "    for folder, count in sorted_counts[:20]:  # Show top 20 folders\n",
        "        print(f\"   {folder}: {count} images\")\n",
        "\n",
        "    if len(sorted_counts) > 20:\n",
        "        print(f\"   ... and {len(sorted_counts) - 20} more folders\")\n",
        "\n",
        "    total = sum(image_counts.values())\n",
        "    print(f\"\\nüéØ GRAND TOTAL: {total} images\")\n",
        "\n",
        "    return total\n",
        "\n",
        "# Get detailed count\n",
        "total_augmented_images = count_images_detailed(augmented_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbP2OwyzlIVg",
        "outputId": "d0469a84-2b1b-4900-fc3c-5b0953289a4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî¢ Detailed image count...\n",
            "\n",
            "üìä IMAGE COUNT BY FOLDER:\n",
            "   JPEGImages: 10668 images\n",
            "\n",
            "üéØ GRAND TOTAL: 10668 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Check what format the augmented dataset is in\n",
        "def check_dataset_format(dataset_path):\n",
        "    print(\"\\nüîç Checking dataset format...\")\n",
        "\n",
        "    # Common dataset structures\n",
        "    structures_found = {\n",
        "        'VOC_format': False,\n",
        "        'YOLO_format': False,\n",
        "        'COCO_format': False,\n",
        "        'TFRecord': False\n",
        "    }\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        # Check for VOC format (ImageSets, Annotations, JPEGImages)\n",
        "        if 'ImageSets' in dirs or 'Annotations' in dirs or 'JPEGImages' in dirs:\n",
        "            structures_found['VOC_format'] = True\n",
        "\n",
        "        # Check for YOLO format (labels folder)\n",
        "        if 'labels' in dirs or any('label' in d.lower() for d in dirs):\n",
        "            structures_found['YOLO_format'] = True\n",
        "\n",
        "        # Check for COCO format (JSON annotations)\n",
        "        if any(f.endswith('.json') and ('instances' in f or 'coco' in f.lower()) for f in files):\n",
        "            structures_found['COCO_format'] = True\n",
        "\n",
        "        # Check for TFRecord\n",
        "        if any(f.endswith('.tfrecord') for f in files):\n",
        "            structures_found['TFRecord'] = True\n",
        "\n",
        "    print(\"\\nüìã DATASET FORMAT:\")\n",
        "    for format_name, found in structures_found.items():\n",
        "        status = \"‚úÖ\" if found else \"‚ùå\"\n",
        "        print(f\"   {status} {format_name}\")\n",
        "\n",
        "    return structures_found\n",
        "\n",
        "# Check format\n",
        "dataset_format = check_dataset_format(augmented_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv1Fe_DzlM82",
        "outputId": "d284c7e9-273a-43af-84d6-89fc8bb69805"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Checking dataset format...\n",
            "\n",
            "üìã DATASET FORMAT:\n",
            "   ‚úÖ VOC_format\n",
            "   ‚ùå YOLO_format\n",
            "   ‚ùå COCO_format\n",
            "   ‚ùå TFRecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Explore the VOC format structure\n",
        "def explore_voc_structure(dataset_path):\n",
        "    print(\"\\nüìÅ Exploring VOC Format Structure...\")\n",
        "\n",
        "    voc_folders = {}\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        # Look for standard VOC directories\n",
        "        if 'Annotations' in dirs:\n",
        "            ann_path = os.path.join(root, 'Annotations')\n",
        "            ann_files = [f for f in os.listdir(ann_path) if f.endswith('.xml')]\n",
        "            voc_folders['Annotations'] = len(ann_files)\n",
        "            print(f\"üìÑ Annotations: {len(ann_files)} XML files\")\n",
        "\n",
        "        if 'JPEGImages' in dirs:\n",
        "            img_path = os.path.join(root, 'JPEGImages')\n",
        "            img_files = [f for f in os.listdir(img_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "            voc_folders['JPEGImages'] = len(img_files)\n",
        "            print(f\"üñºÔ∏è  JPEGImages: {len(img_files)} images\")\n",
        "\n",
        "        if 'ImageSets' in dirs:\n",
        "            sets_path = os.path.join(root, 'ImageSets')\n",
        "            voc_folders['ImageSets'] = True\n",
        "            print(f\"üìä ImageSets: Found\")\n",
        "\n",
        "        # Check for Main directory with train/val splits\n",
        "        main_path = os.path.join(root, 'ImageSets', 'Main')\n",
        "        if os.path.exists(main_path):\n",
        "            train_files = [f for f in os.listdir(main_path) if 'train' in f]\n",
        "            val_files = [f for f in os.listdir(main_path) if 'val' in f or 'test' in f]\n",
        "            print(f\"üìã Train/Val splits: {len(train_files)} train files, {len(val_files)} val files\")\n",
        "\n",
        "    return voc_folders\n",
        "\n",
        "# Explore VOC structure\n",
        "voc_structure = explore_voc_structure(augmented_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0I0qcTalc2d",
        "outputId": "c8eeb84c-6cb1-422c-8b62-426c748d3c72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Exploring VOC Format Structure...\n",
            "üìÑ Annotations: 10668 XML files\n",
            "üñºÔ∏è  JPEGImages: 10668 images\n",
            "üìä ImageSets: Found\n",
            "üìã Train/Val splits: 2 train files, 3 val files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Parse sample VOC annotations to understand the defect classes\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def parse_voc_annotations(dataset_path):\n",
        "    print(\"\\nüîç Parsing VOC Annotations to understand defect classes...\")\n",
        "\n",
        "    # Find Annotations folder\n",
        "    annotations_path = None\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        if 'Annotations' in dirs:\n",
        "            annotations_path = os.path.join(root, 'Annotations')\n",
        "            break\n",
        "\n",
        "    if not annotations_path:\n",
        "        print(\"‚ùå No Annotations folder found!\")\n",
        "        return {}\n",
        "\n",
        "    # Get first few annotation files\n",
        "    xml_files = [f for f in os.listdir(annotations_path) if f.endswith('.xml')][:5]\n",
        "\n",
        "    defect_classes = set()\n",
        "\n",
        "    for xml_file in xml_files:\n",
        "        xml_path = os.path.join(annotations_path, xml_file)\n",
        "        try:\n",
        "            tree = ET.parse(xml_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Extract object names\n",
        "            for obj in root.findall('object'):\n",
        "                name = obj.find('name').text\n",
        "                defect_classes.add(name)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error parsing {xml_file}: {e}\")\n",
        "\n",
        "    print(f\"üéØ Found defect classes: {list(defect_classes)}\")\n",
        "    return defect_classes\n",
        "\n",
        "# Parse annotations\n",
        "defect_classes = parse_voc_annotations(augmented_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsABjh17letQ",
        "outputId": "9b3ebb80-43e0-4b63-c855-b68c38c0c137"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Parsing VOC Annotations to understand defect classes...\n",
            "üéØ Found defect classes: ['missing_hole', 'spur', 'mouse_bite']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Convert VOC format to YOLO format\n",
        "def convert_voc_to_yolo(dataset_path, output_path='/content/PCB_YOLO_Dataset'):\n",
        "    print(\"\\nüîÑ Converting VOC to YOLO format...\")\n",
        "\n",
        "    # Create YOLO directory structure\n",
        "    os.makedirs(os.path.join(output_path, 'images', 'train'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_path, 'images', 'val'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_path, 'labels', 'train'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_path, 'labels', 'val'), exist_ok=True)\n",
        "\n",
        "    # Find VOC directories\n",
        "    voc_dirs = {}\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        if 'Annotations' in dirs:\n",
        "            voc_dirs['annotations'] = os.path.join(root, 'Annotations')\n",
        "        if 'JPEGImages' in dirs:\n",
        "            voc_dirs['images'] = os.path.join(root, 'JPEGImages')\n",
        "        if 'ImageSets' in dirs:\n",
        "            voc_dirs['imagesets'] = os.path.join(root, 'ImageSets')\n",
        "\n",
        "    if not all(key in voc_dirs for key in ['annotations', 'images', 'imagesets']):\n",
        "        print(\"‚ùå Missing required VOC directories! Creating basic structure...\")\n",
        "        return create_basic_yolo_structure(dataset_path, output_path)\n",
        "\n",
        "    # Get class mapping\n",
        "    class_set = set()\n",
        "    for xml_file in os.listdir(voc_dirs['annotations'])[:100]:  # Sample first 100\n",
        "        if xml_file.endswith('.xml'):\n",
        "            xml_path = os.path.join(voc_dirs['annotations'], xml_file)\n",
        "            try:\n",
        "                tree = ET.parse(xml_path)\n",
        "                root = tree.getroot()\n",
        "                for obj in root.findall('object'):\n",
        "                    class_set.add(obj.find('name').text)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    classes = sorted(list(class_set))\n",
        "    class_to_id = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "    print(f\"üéØ Defect classes: {classes}\")\n",
        "\n",
        "    # Process train/val splits\n",
        "    def process_split(split_name, split_file):\n",
        "        split_path = os.path.join(voc_dirs['imagesets'], 'Main', split_file)\n",
        "        if not os.path.exists(split_path):\n",
        "            print(f\"‚ùå Split file not found: {split_path}\")\n",
        "            return 0\n",
        "\n",
        "        processed_count = 0\n",
        "        with open(split_path, 'r') as f:\n",
        "            for line in f:\n",
        "                image_id = line.strip().split()[0]\n",
        "\n",
        "                # Copy image\n",
        "                src_image = os.path.join(voc_dirs['images'], f\"{image_id}.jpg\")\n",
        "                dst_image = os.path.join(output_path, 'images', split_name, f\"{image_id}.jpg\")\n",
        "\n",
        "                if os.path.exists(src_image):\n",
        "                    # Create symbolic link to save space\n",
        "                    if not os.path.exists(dst_image):\n",
        "                        os.symlink(src_image, dst_image)\n",
        "\n",
        "                    # Convert annotation\n",
        "                    src_xml = os.path.join(voc_dirs['annotations'], f\"{image_id}.xml\")\n",
        "                    dst_txt = os.path.join(output_path, 'labels', split_name, f\"{image_id}.txt\")\n",
        "\n",
        "                    if os.path.exists(src_xml):\n",
        "                        convert_voc_xml_to_yolo_txt(src_xml, dst_txt, class_to_id)\n",
        "                        processed_count += 1\n",
        "\n",
        "        return processed_count\n",
        "\n",
        "    # Try to find train/val splits\n",
        "    train_count, val_count = 0, 0\n",
        "\n",
        "    main_dir = os.path.join(voc_dirs['imagesets'], 'Main')\n",
        "    if os.path.exists(main_dir):\n",
        "        for split_file in os.listdir(main_dir):\n",
        "            if 'train' in split_file:\n",
        "                train_count = process_split('train', split_file)\n",
        "            elif 'val' in split_file or 'test' in split_file:\n",
        "                val_count = process_split('val', split_file)\n",
        "\n",
        "    print(f\"‚úÖ Conversion complete!\")\n",
        "    print(f\"   Train: {train_count} images\")\n",
        "    print(f\"   Val: {val_count} images\")\n",
        "    print(f\"   Total: {train_count + val_count} images\")\n",
        "    print(f\"   Classes: {len(classes)}\")\n",
        "\n",
        "    return output_path, classes\n",
        "\n",
        "def convert_voc_xml_to_yolo_txt(xml_path, txt_path, class_to_id):\n",
        "    \"\"\"Convert single VOC XML to YOLO format TXT\"\"\"\n",
        "    try:\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Get image dimensions\n",
        "        size = root.find('size')\n",
        "        width = int(size.find('width').text)\n",
        "        height = int(size.find('height').text)\n",
        "\n",
        "        with open(txt_path, 'w') as f:\n",
        "            for obj in root.findall('object'):\n",
        "                cls_name = obj.find('name').text\n",
        "                if cls_name not in class_to_id:\n",
        "                    continue\n",
        "\n",
        "                cls_id = class_to_id[cls_name]\n",
        "                bbox = obj.find('bndbox')\n",
        "                xmin = float(bbox.find('xmin').text)\n",
        "                ymin = float(bbox.find('ymin').text)\n",
        "                xmax = float(bbox.find('xmax').text)\n",
        "                ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "                # Convert to YOLO format (normalized center x, center y, width, height)\n",
        "                x_center = (xmin + xmax) / 2 / width\n",
        "                y_center = (ymin + ymax) / 2 / height\n",
        "                w = (xmax - xmin) / width\n",
        "                h = (ymax - ymin) / height\n",
        "\n",
        "                f.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error converting {xml_path}: {e}\")\n",
        "\n",
        "# Convert to YOLO format\n",
        "yolo_dataset_path, defect_classes = convert_voc_to_yolo(augmented_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWLXviz6lltM",
        "outputId": "c0dcb25d-809e-47ba-b3ab-a2b189d5d3a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Converting VOC to YOLO format...\n",
            "üéØ Defect classes: ['missing_hole', 'mouse_bite', 'open_circuit', 'short', 'spur', 'spurious_copper']\n",
            "‚úÖ Conversion complete!\n",
            "   Train: 8534 images\n",
            "   Val: 2134 images\n",
            "   Total: 10668 images\n",
            "   Classes: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Create the YAML configuration file for YOLO training\n",
        "def create_yolo_yaml_config(dataset_path, classes, yaml_path='/content/pcb_defects.yaml'):\n",
        "    print(\"\\nüìù Creating YOLO dataset YAML file...\")\n",
        "\n",
        "    # Create class mapping\n",
        "    class_dict = {i: cls_name for i, cls_name in enumerate(classes)}\n",
        "\n",
        "    yaml_content = f\"\"\"# PCB Defects Dataset YAML configuration\n",
        "# Total images: 10,668 (Train: 8,534, Val: 2,134)\n",
        "# Defect classes: 6\n",
        "\n",
        "path: {dataset_path}  # dataset root dir\n",
        "train: images/train   # train images (relative to 'path')\n",
        "val: images/val       # val images (relative to 'path')\n",
        "\n",
        "# Number of classes\n",
        "nc: {len(classes)}\n",
        "\n",
        "# Class names\n",
        "names: {class_dict}\n",
        "\"\"\"\n",
        "\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"‚úÖ YAML configuration created at: {yaml_path}\")\n",
        "    print(f\"üéØ Configuration Summary:\")\n",
        "    print(f\"   - Dataset path: {dataset_path}\")\n",
        "    print(f\"   - Training images: 8,534\")\n",
        "    print(f\"   - Validation images: 2,134\")\n",
        "    print(f\"   - Total images: 10,668\")\n",
        "    print(f\"   - Number of classes: {len(classes)}\")\n",
        "    print(f\"   - Classes: {classes}\")\n",
        "\n",
        "    return yaml_path\n",
        "\n",
        "# Create YAML file\n",
        "yaml_path = create_yolo_yaml_config(yolo_dataset_path, defect_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7F5d52el0KS",
        "outputId": "1b610953-dd55-46ac-cbd4-45f02a8e1bea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Creating YOLO dataset YAML file...\n",
            "‚úÖ YAML configuration created at: /content/pcb_defects.yaml\n",
            "üéØ Configuration Summary:\n",
            "   - Dataset path: /content/PCB_YOLO_Dataset\n",
            "   - Training images: 8,534\n",
            "   - Validation images: 2,134\n",
            "   - Total images: 10,668\n",
            "   - Number of classes: 6\n",
            "   - Classes: ['missing_hole', 'mouse_bite', 'open_circuit', 'short', 'spur', 'spurious_copper']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Verify the final dataset structure\n",
        "def verify_yolo_dataset(dataset_path):\n",
        "    print(\"\\nüîç Verifying YOLO dataset structure...\")\n",
        "\n",
        "    # Check directories exist\n",
        "    required_dirs = [\n",
        "        'images/train',\n",
        "        'images/val',\n",
        "        'labels/train',\n",
        "        'labels/val'\n",
        "    ]\n",
        "\n",
        "    for dir_path in required_dirs:\n",
        "        full_path = os.path.join(dataset_path, dir_path)\n",
        "        if os.path.exists(full_path):\n",
        "            file_count = len([f for f in os.listdir(full_path) if not f.startswith('.')])\n",
        "            print(f\"‚úÖ {dir_path}: {file_count} files\")\n",
        "        else:\n",
        "            print(f\"‚ùå {dir_path}: Missing!\")\n",
        "\n",
        "    # Check sample files\n",
        "    print(\"\\nüìã Sample files check:\")\n",
        "    train_images = os.listdir(os.path.join(dataset_path, 'images', 'train'))[:3]\n",
        "    train_labels = os.listdir(os.path.join(dataset_path, 'labels', 'train'))[:3]\n",
        "\n",
        "    print(f\"Sample train images: {train_images}\")\n",
        "    print(f\"Sample train labels: {train_labels}\")\n",
        "\n",
        "    # Check label format\n",
        "    if train_labels:\n",
        "        sample_label = os.path.join(dataset_path, 'labels', 'train', train_labels[0])\n",
        "        with open(sample_label, 'r') as f:\n",
        "            first_line = f.readline().strip()\n",
        "            print(f\"Sample label format: {first_line}\")\n",
        "\n",
        "# Verify dataset\n",
        "verify_yolo_dataset(yolo_dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAW3xBj8l4OS",
        "outputId": "e1298dfd-bc9a-4fe4-dee1-c8aec94cf3a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Verifying YOLO dataset structure...\n",
            "‚úÖ images/train: 8534 files\n",
            "‚úÖ images/val: 5548 files\n",
            "‚úÖ labels/train: 8534 files\n",
            "‚úÖ labels/val: 5548 files\n",
            "\n",
            "üìã Sample files check:\n",
            "Sample train images: ['l_light_08_spurious_copper_09_5_600.jpg', 'light_04_open_circuit_10_3_600.jpg', 'rotation_270_light_07_missing_hole_04_3_600.jpg']\n",
            "Sample train labels: ['rotation_270_light_04_spur_01_2_600.txt', 'rotation_90_light_08_missing_hole_05_4_600.txt', 'rotation_90_light_12_open_circuit_06_2_600.txt']\n",
            "Sample label format: 4 0.247920 0.714642 0.039933 0.078203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Display detailed dataset statistics\n",
        "def display_dataset_stats(dataset_path, classes):\n",
        "    print(\"\\nüìä DATASET STATISTICS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Count objects per class\n",
        "    class_counts = {cls: 0 for cls in classes}\n",
        "    total_objects = 0\n",
        "\n",
        "    for split in ['train', 'val']:\n",
        "        labels_dir = os.path.join(dataset_path, 'labels', split)\n",
        "        if os.path.exists(labels_dir):\n",
        "            for label_file in os.listdir(labels_dir):\n",
        "                if label_file.endswith('.txt'):\n",
        "                    with open(os.path.join(labels_dir, label_file), 'r') as f:\n",
        "                        for line in f:\n",
        "                            if line.strip():\n",
        "                                cls_id = int(line.strip().split()[0])\n",
        "                                if cls_id < len(classes):\n",
        "                                    class_counts[classes[cls_id]] += 1\n",
        "                                    total_objects += 1\n",
        "\n",
        "    print(f\"üéØ TOTAL DEFECT OBJECTS: {total_objects}\")\n",
        "    print(f\"\\nüìà DEFECTS PER CLASS:\")\n",
        "    for cls, count in class_counts.items():\n",
        "        percentage = (count / total_objects) * 100 if total_objects > 0 else 0\n",
        "        print(f\"   {cls}: {count} objects ({percentage:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nüìÅ DATASET SPLIT:\")\n",
        "    train_imgs = len(os.listdir(os.path.join(dataset_path, 'images', 'train')))\n",
        "    val_imgs = len(os.listdir(os.path.join(dataset_path, 'images', 'val')))\n",
        "    print(f\"   Training: {train_imgs} images\")\n",
        "    print(f\"   Validation: {val_imgs} images\")\n",
        "    print(f\"   Total: {train_imgs + val_imgs} images\")\n",
        "    print(f\"   Train/Val ratio: {train_imgs/val_imgs:.2f}:1\")\n",
        "\n",
        "# Display statistics\n",
        "display_dataset_stats(yolo_dataset_path, defect_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Ix8bL3l8tU",
        "outputId": "e7276210-1ba6-4b7f-8415-a3de50e324cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä DATASET STATISTICS\n",
            "==================================================\n",
            "üéØ TOTAL DEFECT OBJECTS: 28673\n",
            "\n",
            "üìà DEFECTS PER CLASS:\n",
            "   missing_hole: 4791 objects (16.7%)\n",
            "   mouse_bite: 4840 objects (16.9%)\n",
            "   open_circuit: 4758 objects (16.6%)\n",
            "   short: 4653 objects (16.2%)\n",
            "   spur: 4779 objects (16.7%)\n",
            "   spurious_copper: 4852 objects (16.9%)\n",
            "\n",
            "üìÅ DATASET SPLIT:\n",
            "   Training: 8534 images\n",
            "   Validation: 5548 images\n",
            "   Total: 14082 images\n",
            "   Train/Val ratio: 1.54:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Initialize YOLO model for PCB defect detection\n",
        "def initialize_yolo_model():\n",
        "    print(\"\\nüöÄ Initializing YOLO Model for PCB Defect Detection...\")\n",
        "\n",
        "    # Load a pre-trained YOLO model\n",
        "    # You can choose from: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
        "    model = YOLO('yolov8s.pt')  # Using small model for good balance of speed/accuracy\n",
        "\n",
        "    print(\"‚úÖ YOLO model initialized!\")\n",
        "    print(\"üìã Model information:\")\n",
        "    print(f\"   - Model type: YOLOv8s\")\n",
        "    print(f\"   - Input size: 640x640\")\n",
        "    print(f\"   - Pre-trained on: COCO dataset\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize model\n",
        "model = initialize_yolo_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82TCEP5zmAgy",
        "outputId": "1698c618-0793-4194-d54c-bcff91ba319e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Initializing YOLO Model for PCB Defect Detection...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.5MB 193.4MB/s 0.1s\n",
            "‚úÖ YOLO model initialized!\n",
            "üìã Model information:\n",
            "   - Model type: YOLOv8s\n",
            "   - Input size: 640x640\n",
            "   - Pre-trained on: COCO dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Train the YOLO model on PCB defects dataset\n",
        "def train_pcb_detector(model, yaml_path):\n",
        "    print(\"\\nüéØ Starting PCB Defect Detection Training...\")\n",
        "    print(\"‚ö†Ô∏è  This will take some time (30-60 minutes depending on GPU)\")\n",
        "\n",
        "    # Training parameters\n",
        "    training_args = {\n",
        "        'data': yaml_path,           # Dataset configuration\n",
        "        'epochs': 100,               # Number of epochs\n",
        "        'imgsz': 640,                # Image size\n",
        "        'batch': 16,                 # Batch size\n",
        "        'patience': 15,              # Early stopping patience\n",
        "        'save': True,                # Save checkpoints\n",
        "        'device': 0,                 # Use GPU\n",
        "        'workers': 4,                # Data loading workers\n",
        "        'optimizer': 'auto',         # Optimizer\n",
        "        'lr0': 0.01,                 # Initial learning rate\n",
        "        'weight_decay': 0.0005,      # Weight decay\n",
        "        'cos_lr': True,              # Cosine learning rate scheduler\n",
        "        'name': 'pcb_defects_v1'     # Experiment name\n",
        "    }\n",
        "\n",
        "    print(\"üìã Training Configuration:\")\n",
        "    for key, value in training_args.items():\n",
        "        print(f\"   - {key}: {value}\")\n",
        "\n",
        "    print(\"\\n‚è≥ Starting training...\")\n",
        "    results = model.train(**training_args)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Start training (UNCOMMENT WHEN READY)\n",
        "print(\"‚úÖ READY FOR TRAINING!\")\n",
        "print(\"To start training, uncomment the line below:\")\n",
        "print(\"# results = train_pcb_detector(model, yaml_path)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta1b7XulmDfq",
        "outputId": "0fa6fe1b-ae0e-46f0-d2b0-b31ceb2fe285"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ READY FOR TRAINING!\n",
            "To start training, uncomment the line below:\n",
            "# results = train_pcb_detector(model, yaml_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13: Start the PCB Defect Detection Training\n",
        "print(\"üöÄ STARTING TRAINING WITH 10,668 IMAGES!\")\n",
        "print(\"‚è≥ This will take 30-60 minutes depending on your GPU...\")\n",
        "\n",
        "# Start training\n",
        "results = train_pcb_detector(model, yaml_path)\n",
        "\n",
        "print(\"‚úÖ Training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-khsWEGmaKN",
        "outputId": "8fe80d31-d870-4568-9a5e-9057b6e87904"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTING TRAINING WITH 10,668 IMAGES!\n",
            "‚è≥ This will take 30-60 minutes depending on your GPU...\n",
            "\n",
            "üéØ Starting PCB Defect Detection Training...\n",
            "‚ö†Ô∏è  This will take some time (30-60 minutes depending on GPU)\n",
            "üìã Training Configuration:\n",
            "   - data: /content/pcb_defects.yaml\n",
            "   - epochs: 100\n",
            "   - imgsz: 640\n",
            "   - batch: 16\n",
            "   - patience: 15\n",
            "   - save: True\n",
            "   - device: 0\n",
            "   - workers: 4\n",
            "   - optimizer: auto\n",
            "   - lr0: 0.01\n",
            "   - weight_decay: 0.0005\n",
            "   - cos_lr: True\n",
            "   - name: pcb_defects_v1\n",
            "\n",
            "‚è≥ Starting training...\n",
            "Ultralytics 8.3.226 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/pcb_defects.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=pcb_defects_v1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/pcb_defects_v1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 23.3MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2118370  ultralytics.nn.modules.head.Detect           [6, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,137,922 parameters, 11,137,906 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 112.0MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2417.7¬±888.6 MB/s, size: 117.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/PCB_YOLO_Dataset/labels/train... 8534 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8534/8534 2.2Kit/s 3.8s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/PCB_YOLO_Dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1194.5¬±1077.9 MB/s, size: 117.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/PCB_YOLO_Dataset/labels/val... 5548 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5548/5548 1.5Kit/s 3.6s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/PCB_YOLO_Dataset/labels/val.cache\n",
            "Plotting labels to /content/runs/detect/pcb_defects_v1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/pcb_defects_v1\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      3.71G      2.255      3.796      1.428         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.2it/s 2:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.3it/s 52.5s\n",
            "                   all       5548      11358      0.907      0.849      0.912      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100       4.5G      1.825      1.136      1.172         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 51.0s\n",
            "                   all       5548      11358      0.885      0.875      0.912      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      4.52G      1.814      1.106      1.155         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 51.2s\n",
            "                   all       5548      11358      0.856      0.801      0.855      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      4.54G      1.814      1.091      1.156         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 51.1s\n",
            "                   all       5548      11358      0.916      0.881      0.925      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      4.57G      1.782      1.014      1.142         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 51.0s\n",
            "                   all       5548      11358      0.935      0.907      0.943      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      4.59G      1.738     0.9482      1.128         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 50.6s\n",
            "                   all       5548      11358      0.938      0.912      0.954      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      4.62G      1.715     0.9062      1.116         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 50.8s\n",
            "                   all       5548      11358      0.957      0.947       0.97      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      4.64G      1.695      0.882      1.112         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 50.9s\n",
            "                   all       5548      11358       0.96      0.936      0.968      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      4.66G      1.685     0.8593      1.106         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 50.8s\n",
            "                   all       5548      11358      0.965      0.965       0.98      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      4.69G      1.652     0.8226      1.091          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 50.6s\n",
            "                   all       5548      11358      0.966      0.953      0.975      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      4.72G      1.644     0.8215      1.094         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 51.3s\n",
            "                   all       5548      11358      0.967      0.955      0.976       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      4.73G      1.627     0.8034       1.09         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 51.1s\n",
            "                   all       5548      11358      0.922      0.873      0.924      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      4.77G      1.625     0.8062      1.082         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 50.8s\n",
            "                   all       5548      11358        0.8      0.548      0.673      0.246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      4.78G      1.699      1.027       1.11         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.4it/s 50.6s\n",
            "                   all       5548      11358          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      4.81G      1.951      1.862      1.239         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 0.5it/s 5:28\n",
            "                   all       5548      11358          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      4.83G      2.051      2.044       1.29         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.4it/s 2:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 0.9it/s 3:22\n",
            "                   all       5548      11358          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      4.86G      2.099      2.197      1.307         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 1.4it/s 2:06\n",
            "                   all       5548      11358          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      4.88G      2.165      2.555      1.332         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 2.9it/s 1:01\n",
            "                   all       5548      11358    2.8e-06    0.00198   1.28e-06   3.57e-07\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      4.91G      2.215      2.708      1.347         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 2.8it/s 1:01\n",
            "                   all       5548      11358   3.47e-06     0.0027   1.64e-06   4.15e-07\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      4.93G      2.248      2.966      1.311         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 2.8it/s 1:01\n",
            "                   all       5548      11358   8.01e-07    0.00072   4.09e-07   5.59e-08\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      4.96G      2.547      3.958      1.427         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 2.3it/s 1:16\n",
            "                   all       5548      11358   3.32e-05   0.000267   1.66e-05   1.68e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      4.98G      2.587      4.006      1.382          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 2.6it/s 1:08\n",
            "                   all       5548      11358   2.33e-06    0.00207   1.19e-06   3.43e-07\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      5.01G      2.607      4.252      1.436         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 1.2it/s 2:20\n",
            "                   all       5548      11358   9.82e-07    0.00045   4.93e-07   7.87e-08\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      5.03G      2.662      4.452      1.438         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 534/534 3.5it/s 2:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 0.8it/s 3:43\n",
            "                   all       5548      11358   1.41e-05    0.00036   1.56e-06   4.05e-07\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 9, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "24 epochs completed in 1.615 hours.\n",
            "Optimizer stripped from /content/runs/detect/pcb_defects_v1/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from /content/runs/detect/pcb_defects_v1/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating /content/runs/detect/pcb_defects_v1/weights/best.pt...\n",
            "Ultralytics 8.3.226 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 174/174 3.2it/s 54.4s\n",
            "                   all       5548      11358      0.964      0.965       0.98      0.517\n",
            "          missing_hole        951       1918      0.966      0.995      0.985      0.576\n",
            "            mouse_bite        994       1959      0.969      0.975      0.983      0.516\n",
            "          open_circuit        898       1870      0.969      0.974      0.982      0.478\n",
            "                 short        894       1851      0.976      0.962      0.975      0.519\n",
            "                  spur        916       1908      0.947      0.934      0.971      0.487\n",
            "       spurious_copper        895       1852      0.959      0.948      0.982      0.523\n",
            "Speed: 0.2ms preprocess, 4.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/pcb_defects_v1\u001b[0m\n",
            "‚úÖ Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Load your TRAINED model\n",
        "print(\"üéØ Loading your TRAINED PCB Defect Detector...\")\n",
        "best_model_path = \"/content/runs/detect/pcb_defects_v1/weights/best.pt\"\n",
        "trained_model = YOLO(best_model_path)\n",
        "\n",
        "class PCBDefectDetector:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.defect_classes = {\n",
        "            0: \"missing_hole\",\n",
        "            1: \"mouse_bite\",\n",
        "            2: \"open_circuit\",\n",
        "            3: \"short\",\n",
        "            4: \"spur\",\n",
        "            5: \"spurious_copper\"\n",
        "        }\n",
        "        print(\"‚úÖ Trained model loaded successfully!\")\n",
        "\n",
        "    def analyze_pcb(self, image):\n",
        "        # Convert PIL Image to numpy array if needed\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = np.array(image)\n",
        "\n",
        "        # Run detection with your TRAINED model\n",
        "        results = self.model(image)\n",
        "        r = results[0]\n",
        "\n",
        "        # Create visualization with bounding boxes\n",
        "        result_image = r.plot()\n",
        "        result_image_rgb = result_image[..., ::-1]  # BGR to RGB\n",
        "\n",
        "        # Count defects\n",
        "        defect_count = len(r.boxes)\n",
        "        defect_types = {}\n",
        "        defect_details = []\n",
        "\n",
        "        if defect_count > 0:\n",
        "            for i, box in enumerate(r.boxes):\n",
        "                class_id = int(box.cls[0])\n",
        "                defect_name = self.defect_classes.get(class_id, f\"class_{class_id}\")\n",
        "                confidence = float(box.conf[0])\n",
        "                defect_types[defect_name] = defect_types.get(defect_name, 0) + 1\n",
        "                defect_details.append({\n",
        "                    'defect': defect_name,\n",
        "                    'confidence': f\"{confidence:.2f}\",\n",
        "                    'position': f\"Box {i+1}\"\n",
        "                })\n",
        "\n",
        "        return result_image_rgb, defect_count, defect_types, defect_details\n",
        "\n",
        "# Initialize with your trained model\n",
        "detector = PCBDefectDetector(trained_model)\n",
        "\n",
        "def gradio_analyze_pcb(input_image):\n",
        "    \"\"\"Gradio interface function for PCB analysis\"\"\"\n",
        "    try:\n",
        "        # Analyze the image with your TRAINED model\n",
        "        result_image, defect_count, defect_types, defect_details = detector.analyze_pcb(input_image)\n",
        "\n",
        "        # Convert numpy array to PIL Image for Gradio\n",
        "        result_pil = Image.fromarray(result_image)\n",
        "\n",
        "        # Create result text\n",
        "        if defect_count == 0:\n",
        "            result_text = \"‚úÖ **PCB Status: EXCELLENT**\\n\\nNo defects detected! This PCB is in perfect condition.\"\n",
        "            status = \"GOOD\"\n",
        "            color = \"green\"\n",
        "        else:\n",
        "            result_text = f\"‚ùå **PCB Status: DEFECTIVE**\\n\\n**Total Defects Found: {defect_count}**\\n\\n\"\n",
        "            result_text += \"**Defects Breakdown:**\\n\"\n",
        "            for defect, count in defect_types.items():\n",
        "                result_text += f\"‚Ä¢ {defect}: {count} locations\\n\"\n",
        "\n",
        "            result_text += f\"\\n**Detection Confidence:**\\n\"\n",
        "            for detail in defect_details:\n",
        "                result_text += f\"- {detail['defect']}: {detail['confidence']}\\n\"\n",
        "\n",
        "            status = \"DEFECTIVE\"\n",
        "            color = \"red\"\n",
        "\n",
        "        return result_pil, result_text\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"‚ùå Error analyzing image: {str(e)}\"\n",
        "        return input_image, error_msg\n",
        "\n",
        "# Create Simple Gradio Interface\n",
        "print(\"üöÄ Launching PCB Defect Detector Interface...\")\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=gradio_analyze_pcb,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"üì§ Upload PCB Image\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"üîç Detection Results\"),\n",
        "        gr.Textbox(label=\"üìä Analysis Report\", lines=10)\n",
        "    ],\n",
        "    title=\"üîç PCB Defect Detector - TRAINED MODEL\",\n",
        "    description=\"**Upload a PCB image to detect defects with 98% accuracy!**\\nTrained on 10,668+ PCB images ‚Ä¢ Detects 6 defect types\",\n",
        "    examples=[],  # You can add example images here\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "print(\"‚úÖ Interface ready! Opening web app...\")\n",
        "interface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WtDCj6SUIh1c",
        "outputId": "4bf18755-5f84-4bd1-cc62-5aeceede014d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Loading your TRAINED PCB Defect Detector...\n",
            "‚úÖ Trained model loaded successfully!\n",
            "üöÄ Launching PCB Defect Detector Interface...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Interface ready! Opening web app...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://9a0ca20796281bf215.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9a0ca20796281bf215.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 125, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 111, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 391, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7f2477a8a420 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 352x640 1 open_circuit, 45.7ms\n",
            "Speed: 2.2ms preprocess, 45.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 125, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 111, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 391, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7f2477a8a420 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 352x640 1 open_circuit, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 125, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 111, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 391, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7f2477a8a420 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 352x640 1 missing_hole, 44.2ms\n",
            "Speed: 2.9ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 125, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 111, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 391, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7f2477a8a420 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 352x640 3 missing_holes, 50.0ms\n",
            "Speed: 2.5ms preprocess, 50.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 0.0.0.0:7860 <> https://12b51b5beeb7f59dea.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://9a0ca20796281bf215.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Save your trained model to Google Drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy your trained model\n",
        "trained_model_path = \"/content/runs/detect/pcb_defects_v1/weights/best.pt\"\n",
        "drive_folder = \"/content/drive/MyDrive/PCB_Defect_Detector\"\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "shutil.copy2(trained_model_path, os.path.join(drive_folder, \"pcb_model.pt\"))\n",
        "\n",
        "print(\"‚úÖ Model saved to Google Drive!\")\n",
        "print(\"üìç Path: /content/drive/MyDrive/PCB_Defect_Detector/pcb_model.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmQuOj-eNGB9",
        "outputId": "b11c8e4e-ccb6-4e43-930f-f00c26290e08"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Model saved to Google Drive!\n",
            "üìç Path: /content/drive/MyDrive/PCB_Defect_Detector/pcb_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Use this SIMPLE code whenever you need it\n",
        "from google.colab import drive\n",
        "import gradio as gr\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Load your trained model\n",
        "model_path = \"/content/drive/MyDrive/PCB_Defect_Detector/pcb_model.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "print(\"‚úÖ Trained model loaded!\")\n",
        "\n",
        "# 3. Simple analysis function\n",
        "def analyze_pcb(image):\n",
        "    # Run detection\n",
        "    results = model(image)\n",
        "\n",
        "    # Get first result\n",
        "    r = results[0]\n",
        "\n",
        "    # Show image with boxes\n",
        "    result_image = r.plot()\n",
        "    result_image = result_image[..., ::-1]  # BGR to RGB\n",
        "\n",
        "    # Count defects\n",
        "    defect_count = len(r.boxes)\n",
        "    defects = {}\n",
        "\n",
        "    for box in r.boxes:\n",
        "        class_id = int(box.cls[0])\n",
        "        defect_names = [\"missing_hole\", \"mouse_bite\", \"open_circuit\", \"short\", \"spur\", \"spurious_copper\"]\n",
        "        defect_name = defect_names[class_id]\n",
        "        defects[defect_name] = defects.get(defect_name, 0) + 1\n",
        "\n",
        "    # Create result text\n",
        "    if defect_count == 0:\n",
        "        result_text = \"‚úÖ No defects found - PCB is GOOD\"\n",
        "    else:\n",
        "        result_text = f\"‚ùå Found {defect_count} defects:\\n\"\n",
        "        for defect, count in defects.items():\n",
        "            result_text += f\"‚Ä¢ {defect}: {count}\\n\"\n",
        "\n",
        "    return Image.fromarray(result_image), result_text\n",
        "\n",
        "# 4. Create simple interface\n",
        "interface = gr.Interface(\n",
        "    fn=analyze_pcb,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"üì§ Upload PCB Image\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"üîç Result\"),\n",
        "        gr.Textbox(label=\"üìä Analysis\")\n",
        "    ],\n",
        "    title=\"PCB Defect Detector\",\n",
        "    description=\"Upload PCB image to detect defects\"\n",
        ")\n",
        "\n",
        "# 5. Launch\n",
        "print(\"üöÄ Starting PCB Detector...\")\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "9GcFagGFNONW",
        "outputId": "8201caf3-3788-4887-fd04-a76d8bfedc9a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Trained model loaded!\n",
            "üöÄ Starting PCB Detector...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6cb1d8a2eaa93e453a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6cb1d8a2eaa93e453a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}